## Reproducing Section 6.4: Profiling DPU

Navigation: [Table of contents], [Previous section]

[Table of contents]: 1-intro.md#index
[Previous section]: 5-section-6.3.md

Section 6.4 of the paper states a number of experimental conclusions about
the percentage of the run time spent in the most important sub-procedures
implemented by DPU.
In the sections below we address each of the claims made in paper.

We use [Callgrind] and [KCachegrind] to validate our statements. DPU comes with
a handy commandline option `--callgrind` which, when passed to DPU, will run DPU
under `callgrind`.

The benchmarks used for these experiments are as follows:

```sh
$ cd sec6.4-profiling/
$ ls -l
[LIST HERE]
```

We run DPU in with optimal POR exploration (`-k 0`).
For simplicity of evaluation we include the `callgrind.out.*` files generated by
`callgrind` when DPU is ran on the above benchmarks. The files are available in
the [folder callgrind](https://github.com/cesaro/dpu-cav18-exp/tree/master/sec6.4-profiling/callgrind.out),
but can be generated as follows:

```sh
dpu ./cav18/bench/multiprodcon.c -k 0 --callgrind
```

[Callgrind]: http://valgrind.org/docs/manual/cl-manual.html
[KCachegrind]: http://kcachegrind.sourceforge.net/

### Callgrind + KCachegrind Premiere

After running **dpu** on benchmarks with *--callgrind*, you can read `callgrind.out` profiling
files using a text editor, but **KCacheGrind** will be more useful thank to visual view.
You can launch **KCacheGrind** using command line, providing your system installed it.
Here is the command to view the profilling file `callgrind.out.mpc`  achieved by the command
running DPU on the benchmark *multiprodcon.c*
```sh
kcachegrind callgrind.out.mpc
```
Note that to be able to launch GUI of **kcachegrind** in your local Linux machine while working on
a virtual machine (here is our cloud virtual machine), you should connect to it with:
```sh
ssh - X  VM-link
```
The first screen presents a list of all the profiled procedures as the image below
![](img/main-screen.png)

* The left panel displays major functions in order where you are highlighted
at main function by default. You can search in the top left box for require function.
* The details of selected function ( Here is `dpu::C15unfolder::explore()` we
have searched for) are  in the right panel which is devided in two parts: upper one
for callers where we can see the `dpu::main(int,char**)` as caller of `dpu::C15unfolder::explore()`
and the lower for callees where we concern for Call Graph and All Callees.

![](img/explore-callgraph.png)

The  *Call Graph* tab shows us  the hierachy of major called functions together with their
performance in term of percentage (relative to parent) or  the number of instruction fetch cost.
In this example, we see three sub-functions of `dpu::C15unfolder::explore()`:
`stid::Executor::run()` takes 60.10%, `dpu::C15unfolder::stream_to_events()`
takes 13.54% and `dpu::C15unfolder::find_alternative()` takes 18.86% the run time of
their parent.
Other minor functions are skipped, but you can find some of them in the list in *All Callees* tab
or just do a search in the left panel.

### Claim 1:  DPU spends between 30% and 90% of the time running the program under anlaysis.
The main procedure of DPU is the function `dpu::explore()` responsible for running program
to get a maximal configuration, then compute alternatives for exploring another branch of the unfolding.
To run program under analysis, DPU calls front end Steroids function `stid::Executor::run()` to \
execute the benchmarks ( as C multithreaded programs) to get a *stream of actions*. This function counts
for 30% to 90% (65% in average) of the DPU run time.

| Benchmarks  | Executing C program (%) |
| ------------     | --------  |
| DISP (5,3)      |  47.08   |
| MPC(3,5)       |  60.10   |
| PI(5)               |  70.74   |
| PI(6)               |  64.34   |
| MPAT(6)         |  54.97   |
| POL(7,3)        |  34.43   |

Some representative results in the above table support what we mention in Section 6.4 of the paper
about program executing time.
### Claim 2: DPU spends in average 65% of the time running the program under anlaysis


### Claim 3: DPU spends between 15% and 30% of the time adding events to the
event structure.
| Benchmarks  |  Add events (%) |
| ----------------| ------------------|
| DISP (5,3)      |    23.00               |
| MPC(3,5)       |    13.54               |
| PI(5)               |    21.63               |
| PI(6)               |    22.58               |
| MPAT()           |    24.52               |
| POL(7,3)        |    27.76               |

### Claim 4: DPU spends between 1% and 50% of the time adding spikes to the comb

| Benchmarks  |  Add spikes (%) |
| --------------- | -------------- |
| DISP (5,3)      |   18.01          |
| MPC()            |   15.28          |
| PI(5)               |    0.75           |
| PI(6)               |    1.62           |
| MPAT()           |    13.97         |
| POL(7,3)        |    35.02         |

### Claim 5: DPU spends less than 5% of the time solving the comb

Benchmarks  |   Explore comb (%) |
| --------------|  --------------- |
| DISP (5,3)    |    1                 |
| MPC()          |     0.5             |
| PI(5)             |     0.5             |
| PI(6)             |     0.5             |
| MPAT()         |     0.74           |
| POL(7,3)      |     1                |

### Claim 6: DPU spends less than 5% of the time computing conflicting extensions

| Benchmarks  |  Compute conflicting extension (%) |
| ----------------| ---------------------------------------|
| DISP (5,3)      |    3.9              |
| MPC(3,5)       |   3.55             |
| PI(5)               |   3.31             |
| PI(6)               |   8.94             |
| MPAT()           |   3.4               |
| POL(7,3)        |   2.67             |


### Claim 2:  Computing alternatives
The seconde major procedure of DPU is computing alternatives including two sub main procesures:
prepare the event structure (maximal configuration and conflicting extension)  and find an alternative.
Preparing event structure does:
* Adding events to the event structure: stream of actions achieved from `stid::Executor::run()`
are converted into events, then added to the unfolding. This work corresponds to the  function
`dpu::C15unfolder::stream_to_events()` , a callee of `dpu::C15unfolder::explore()`
* Computing conflicting extensions: We have function `dpu::C15unfolder::compute_cex()`
to do that work which usually takes a tiny amount of time to finish.

| Benchmarks  |  Add events (%) | Compute conflicting extension (%) |
| ----------------| ------------------| ----------------------------------------|
| DISP (5,3)      |    23.00               |    3.9               |
| MPC(3,5)       |    13.54               |    3.55             |
| PI(5)               |    21.63               |    3.31             |
| PI(6)               |    22.58               |    8.94             |
| MPAT()           |    24.52               |    3.4               |
| POL(7,3)        |    27.76               |    2.67             |

The table shows adding events to the event structure  counts for around 15% to 30% while
computing conflicting extensions normally takes less than 5%, except benchmark PI with 6 threads.

### Claim 3: Find an alternative
To find an alternative, we exploit the *comb* whose spikes are sets of events immediately conflicts with
events in disable set. To evaluate the alternative finding performance, we look for functions:
* Building the comb: reseting the comb `Comb::clear()`, adding spikes `Comb::add_spike()`, checking if each
element in a spike is in conflict with some event in the configuration `dpu::Primecon::in_cfl_with()` and
poping up events from spikes`pop_back()` . Among them,  `Comb::clear()` and `pop_back()`are usually tiny,
so often inlined in **Kcachegrind** view.
* Searching for solutions in the comb  by the function `dpu::C15unfolder::enumerate_combination()`.

We get some representative results in the table below:

| Benchmarks  |  Build comb (%) | Explore comb (%) |
| --------------- | -------------- | ---------------- |
| DISP (5,3)      |   18.01          |  1           |    ok
| MPC()            |   15.28          |  0.5        | ok
| PI(5)               |    0.75           |  0.5        | ok
| PI(6)               |    1.62           |  0.5        | ok
| MPAT()           |    13.97         |  0.74       ok
| POL(7,3)        |    35.02         |  1           | ok

The results conforms to the conclusion in Section 6.4 that building the spikes of a new
comb varies from 1% to 50% and searching for solutions in the comb is less than 5%
(They are here even less than 1%).



