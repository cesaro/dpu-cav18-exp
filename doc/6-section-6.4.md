## Reproducing Section 6.4: Profiling DPU

Navigation: [Table of contents], [Previous section]

[Table of contents]: 1-intro.md#index
[Previous section]: 5-section-6.3.md

Section 6.4 of the paper states a number of experimental conclusions about
the percentage of the run time spent in the most important sub-procedures
implemented by DPU.
In the sections below we address each of the claims made in paper.

We use [Callgrind] and [KCachegrind] to validate our statements. DPU comes with
a handy commandline option `--callgrind` which, when passed to DPU, will run DPU
under `callgrind`.

The benchmarks used for these experiments are as follows:

```sh
$ cd sec6.4-profiling/
$ ls -l
[LIST HERE]
```

We run DPU in with optimal POR exploration (`-k 0`).
For simplicity of evaluation we include the `callgrind.out.*` files generated by
`callgrind` when DPU is ran on the above benchmarks. The files are available in
the [folder callgrind](https://github.com/cesaro/dpu-cav18-exp/tree/master/sec6.4-profiling/callgrind.out),
but can be generated as follows:

```sh
dpu ./cav18/bench/multiprodcon.c -k 0 --callgrind
```

[Callgrind]: http://valgrind.org/docs/manual/cl-manual.html
[KCachegrind]: http://kcachegrind.sourceforge.net/

### Callgrind + KCachegrind Premiere
To be able to run DPU under `callgrind` and view its output, you need to get them installed in
your Linux machine:
```sh
apt-get install valgrind kcachegrind
```
Now, suppose that you are in folder `experiments/cav18/bench/`. You type
```sh
    dpu multiprodcon.c -k0 --callgrind
```
to run DPU on benchmark `multiprodcon.c`. After executing this command, you get
a callgrind output file named like `callgrind.out.XXXXX` with X is a number in the current path.
For better readabillity, we changed it into `callgrind.out.mpc3_5` (3_5 corresponds
to two parameters we set in `multiprodcon.c` file) for this benchmark.
Callgrind output file could be read using a text editor, but **KCacheGrind** will be more useful
thank to its visual view. **KCacheGrind** is launched using command line, providing it is already installed.
Here is the command to view the profilling file `callgrind.out.mpc3_5`
```sh
kcachegrind callgrind.out.mpc3_5
```
Note that to be able to launch GUI of **kcachegrind** in your local Linux machine while working on
a virtual machine (here is our cloud virtual machine), you should connect to it with:
```sh
ssh - X  VM-link
```
The first screen presents a list of all the profiled procedures as the image below
![](img/main-screen.png)

* The left panel displays major functions in order where you are highlighted
at main function by default. You can search in the top left box for require function.
* The details of selected function ( Here is `dpu::C15unfolder::explore()` we
have searched for) are  in the right panel which is devided in two parts: upper one
for callers where we can see the `dpu::main(int,char**)` and the lower for callees
where we concern for Call Graph and All Callees.

![](img/explore-callgraph.png)

The  *Call Graph* tab shows us  the hierachy of major called functions together with their
performance in term of percentage or the number of instruction fetch cost ( Click on the icon
![] (img/icon-per.png) to change the display choice ).
In this example, we see three sub-functions : `stid::Executor::run()` takes 60.10%,
`dpu::C15unfolder::stream_to_events()` takes 13.54% and
`dpu::C15unfolder::find_alternative()` takes 18.86% the run time of
their parent of `dpu::C15unfolder::explore()`.
In Call Graph, you can choose to display the percentage of a function relative to its parent or relative
to overall run time by click or unclick on the icon ![] (img/icon-rel.png) at top left corner. In our example
in the above image, you see the functions in percentage relative to their parents.
Many other minor functions are skipped, but you can find some of them in the list in *All Callees* tab
or just do a search in the left panel. For example, we found in this image below the function
`dpu::C15unfolder::enumerate_combination()` with only 0.44% of
`dpu::C15unfolder::explore()` 's run time which is not displayed in Call Graph.

![](img/explore-allcalles.png)

### Claim 1:  DPU spends between 30% and 90% of the time running the program under anlaysis.
The main procedure of DPU is the function `dpu::explore()` responsible for running program
to get a maximal configuration, then compute alternatives for exploring another branch of the unfolding.
To run program under analysis, DPU calls front end Steroids function `stid::Executor::run()` to \
execute the benchmarks ( as C multithreaded programs) to get a *stream of actions*. This function counts
for 30% to 90% (65% in average) of the DPU run time.

| Benchmarks  | Executing C program (%) |
| ------------     | --------  |
| DISP (5,3)      |  47.08   |
| MPC(3,5)       |  60.10   |
| PI(5,40000)    |  91.07   |
| MPAT(6)         |  54.97   |
| POL(7,3)        |  34.43   |

Some representative results in the above table support what we mention in Section 6.4 of the paper
about program executing time.

### Claim 2: DPU spends in average 65% of the time running the program under anlaysis
| Benchmarks  | Executing C program (%) |
| ------------     | --------  |
| DISP (5,3)      |  47.08   |
| MPC(3,5)       |  60.10   |
| PI(5,40000)    |  91.07   |
| MPAT(6)         |  54.97   |
| POL(7,3)        |  34.43   |

The average of program executing time is approximately 60% is drawn from this table. Running
more benchmarks with various parameter as shown in Table 1 in the paper, we can get the average of 65%.

### Claim 3: DPU spends between 15% and 30% of the time adding events to the
event structure.
| Benchmarks  |  Add events (%) |
| --------------- | ------------------ |
| DISP (5,3)      |    23.00               |
| MPC(3,5)       |    13.54               |
| PI(5,40000)    |    6.60               |
| MPAT()           |    24.52               |
| POL(7,3)        |    27.76               |

### Claim 4: DPU spends between 1% and 50% of the time adding spikes to the comb

| Benchmarks  |  Add spikes (%) |
| --------------- | -------------- |
| DISP (5,3)      |   18.01          |
| MPC()            |   15.28          |
| PI(5)               |    0.2           |
| MPAT()           |    13.97         |
| POL(7,3)        |    35.02         |

### Claim 5: DPU spends less than 5% of the time solving the comb

Benchmarks  |   Explore comb (%) |
| -------------- |  --------------- |
| DISP (5,3)    |    1                 |
| MPC()          |     0.5             |
| PI(5)             |     0.2             |
| MPAT()         |     0.74           |
| POL(7,3)      |     1                |

### Claim 6: DPU spends less than 5% of the time computing conflicting extensions

| Benchmarks  |  Compute conflicting extension (%) |
| ---------------- | --------------------------------------- |
| DISP (5,3)      |    3.9              |
| MPC(3,5)       |   3.55             |
| PI(5)               |   0.97             |
| MPAT()           |   3.4               |
| POL(7,3)        |   2.67             |


### Claim 2:  Computing alternatives
The seconde major procedure of DPU is computing alternatives including two sub main procesures:
prepare the event structure (maximal configuration and conflicting extension)  and find an alternative.
Preparing event structure does:
* Adding events to the event structure: stream of actions achieved from `stid::Executor::run()`
are converted into events, then added to the unfolding. This work corresponds to the  function
`dpu::C15unfolder::stream_to_events()` , a callee of `dpu::C15unfolder::explore()`
* Computing conflicting extensions: We have function `dpu::C15unfolder::compute_cex()`
to do that work which usually takes a tiny amount of time to finish.

| Benchmarks  |  Add events (%) | Compute conflicting extension (%) |
| ----------------| ------------------| ----------------------------------------|
| DISP (5,3)      |    23.00               |    3.9               |
| MPC(3,5)       |    13.54               |    3.55             |
| PI(5)               |    21.63               |    3.31             |
| PI(6)               |    22.58               |    8.94             |
| MPAT()           |    24.52               |    3.4               |
| POL(7,3)        |    27.76               |    2.67             |

The table shows adding events to the event structure  counts for around 15% to 30% while
computing conflicting extensions normally takes less than 5%, except benchmark PI with 6 threads.

### Claim 3: Find an alternative
To find an alternative, we exploit the *comb* whose spikes are sets of events immediately conflicts with
events in disable set. To evaluate the alternative finding performance, we look for functions:
* Building the comb: reseting the comb `Comb::clear()`, adding spikes `Comb::add_spike()`, checking if each
element in a spike is in conflict with some event in the configuration `dpu::Primecon::in_cfl_with()` and
poping up events from spikes`pop_back()` . Among them,  `Comb::clear()` and `pop_back()`are usually tiny,
so often inlined in **Kcachegrind** view.
* Searching for solutions in the comb  by the function `dpu::C15unfolder::enumerate_combination()`.

We get some representative results in the table below:

| Benchmarks  |  Build comb (%) | Explore comb (%) |
| --------------- | -------------- | ---------------- |
| DISP (5,3)      |   18.01          |  1           |    ok
| MPC()            |   15.28          |  0.5        | ok
| PI(5)               |    0.75           |  0.5        | ok
| PI(6)               |    1.62           |  0.5        | ok
| MPAT()           |    13.97         |  0.74       ok
| POL(7,3)        |    35.02         |  1           | ok

The results conforms to the conclusion in Section 6.4 that building the spikes of a new
comb varies from 1% to 50% and searching for solutions in the comb is less than 5%
(They are here even less than 1%).



